{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "import imutils\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import picklefrom imutils import paths\n",
        "from imutils import paths\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.src.callbacks import History\n",
        "from PIL import Image\n",
        "from PIL import ImageFilter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "pgw2AQ2W8pRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRATAR IMAGEM\n",
        "\n",
        "def prepare_image(img):\n",
        "    img = img.filter(ImageFilter.SMOOTH_MORE)\n",
        "    img = img.filter(ImageFilter.SMOOTH_MORE)\n",
        "    if 'L' != img.mode:\n",
        "        img.convert(\"L\")\n",
        "    return img\n",
        "\n",
        "def remove_noise(img, pass_factor):\n",
        "\n",
        "    for column in range(img.size[0]):\n",
        "        for line in range(img.size[1]):\n",
        "            value = remove_noise_by_pixel(img, column, line, pass_factor)\n",
        "            img.putpixel((column, line), value)\n",
        "\n",
        "    return img\n",
        "\n",
        "def remove_noise_by_pixel(img, column, line, pass_factor):\n",
        "\n",
        "    if img.getpixel((column, line)) < pass_factor:\n",
        "        return (0)\n",
        "    return (255)\n",
        "\n",
        "def tratar_imagem(noise, arquivo_origem, arquivo_destino=\"tratado\"):\n",
        "\n",
        "    arquivos = glob.glob(f'{arquivo_origem}/*')\n",
        "\n",
        "    for arquivo in arquivos:\n",
        "        imagem = cv2.imread(arquivo)\n",
        "        imagem_cinza = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
        "        _, imagem_tratada=  cv2.threshold(imagem_cinza,127,255, cv2.THRESH_BINARY or cv2.THRESH_OTSU)\n",
        "        nome_arquivo = os.path.basename(arquivo)\n",
        "        cv2.imwrite(f\"{arquivo_destino}/{nome_arquivo}\", imagem_tratada)\n",
        "\n",
        "    arquivos = glob.glob(f'{arquivo_destino}/*')\n",
        "\n",
        "    for arquivo in arquivos:\n",
        "        imagem = Image.open(arquivo)\n",
        "        imagem = prepare_image(imagem)\n",
        "        imagem = remove_noise(imagem, noise)\n",
        "        imagem2 = Image.new(\"P\", imagem.size, 255)\n",
        "\n",
        "        for x in range(imagem.size[1]):\n",
        "            for y in range(imagem.size[0]):\n",
        "                cor_pixel = imagem.getpixel((y,x))\n",
        "                if cor_pixel < 127:\n",
        "                    imagem2.putpixel((y,x), 0)\n",
        "\n",
        "        for x in range(imagem2.size[1]):\n",
        "            for y in range(imagem2.size[0]):\n",
        "                cor_pixel = imagem2.getpixel((y,x))\n",
        "                if cor_pixel == 255:\n",
        "                    imagem2.putpixel((y,x), 0)\n",
        "                else:\n",
        "                    imagem2.putpixel((y,x), 255)\n",
        "\n",
        "        if imagem2.mode != 'RGB':\n",
        "            imagem2 = imagem2.convert('RGB')\n",
        "        imagem2.save(arquivo)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    tratar_imagem(90, \"/content/imagens\", arquivo_destino=\"/content/imagens_tratadas\")"
      ],
      "metadata": {
        "id": "6aRT9AtsBd7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SEPARAR AS LETRAS DE CADA CAPTCHA\n",
        "def separar_letras(area_ret, tratado_file, origem, letter, calculo, metodo):\n",
        "    arquivos = glob.glob(f\"{tratado_file}/*\")\n",
        "\n",
        "    for arquivo in arquivos:\n",
        "        imagem = cv2.imread(arquivo)\n",
        "        imagem = cv2.cvtColor(imagem, cv2.COLOR_RGB2GRAY)\n",
        "        _, imagem = cv2.threshold(imagem, 0, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "        contornos, _ = cv2.findContours(imagem, calculo, metodo)\n",
        "\n",
        "        #for i, contour in enumerate(contornos):\n",
        "        #   x, y, w, h = cv2.boundingRect(contour)\n",
        "        #  cv2.rectangle(imagem, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
        "        regiao_letras = []\n",
        "\n",
        "        for i,contorno in enumerate(contornos):\n",
        "\n",
        "            (x, y, l, a) = cv2.boundingRect(contorno)\n",
        "            area = cv2.contourArea(contorno)\n",
        "            if area > area_ret and x > 0 and y > 0:\n",
        "                regiao_letras.append((x,y,l,a))\n",
        "\n",
        "\n",
        "        imagem_final = cv2.merge([imagem] * 3)\n",
        "        i=0\n",
        "\n",
        "        for retangulo in regiao_letras:\n",
        "            x,y, largura, altura = retangulo\n",
        "            imagem_letra = imagem[y-2:y+altura + 2, x-1:x+largura+1]\n",
        "            i+=1\n",
        "            nome_arquivo = os.path.basename(arquivo).replace(\".png\", f\"letra{i}.png\")\n",
        "            cv2.imwrite(f\"./{letter}/{nome_arquivo}\", imagem_letra)\n",
        "            cv2.rectangle(imagem_final, (x-2, y-2), (x + largura + 2, y + altura + 2), (255, 0, 0), 1)\n",
        "        nome_arquivo = os.path.basename(arquivo)\n",
        "        cv2.imwrite(f\"./{origem}/{nome_arquivo}\", imagem_final)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    separar_letras(90, \"imagens_tratadas\", \"imagens_identificadas\", \"imagens_letras\", cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)"
      ],
      "metadata": {
        "id": "tZtS7pLc3C69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  - RECSIZE_TO_FIT\n",
        "\n",
        "def resize_to_fit(image, width, height):\n",
        "\n",
        "    # grab the dimensions of the image, then initialize\n",
        "    # the padding values\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    # if the width is greater than the height then resize along\n",
        "    # the width\n",
        "    if w > h:\n",
        "        image = imutils.resize(image, width=width)\n",
        "\n",
        "    # otherwise, the height is greater than the width so resize\n",
        "    # along the height\n",
        "    else:\n",
        "        image = imutils.resize(image, height=height)\n",
        "\n",
        "    # determine the padding values for the width and height to\n",
        "    # obtain the target dimensions\n",
        "    padW = int((width - image.shape[1]) / 2.0)\n",
        "    padH = int((height - image.shape[0]) / 2.0)\n",
        "\n",
        "    # pad the image then apply one more resizing to handle any\n",
        "    # rounding issues\n",
        "    image = cv2.copyMakeBorder(image, padH, padH, padW, padW,\n",
        "        cv2.BORDER_REPLICATE)\n",
        "    image = cv2.resize(image, (width, height))\n",
        "\n",
        "    # return the pre-processed image\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "4l9IStFkTKg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.callbacks import History\n",
        "##  - TREINAR\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def treinar(number_options, letter_file, nome_ia, nome_modelo):\n",
        "\n",
        "    dados = []\n",
        "    rotulos = []\n",
        "    pasta_base_imagens = letter_file\n",
        "\n",
        "    imagens = paths.list_images(pasta_base_imagens)\n",
        "\n",
        "    for arquivo in imagens:\n",
        "        rotulo = arquivo.split(os.path.sep)[-2]\n",
        "        imagem = cv2.imread(arquivo)\n",
        "        imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2GRAY)\n",
        "        imagem = resize_to_fit(imagem, 20, 20)\n",
        "        imagem = np.expand_dims(imagem, axis=2)\n",
        "\n",
        "        dados.append(imagem)\n",
        "        rotulos.append(rotulo)\n",
        "\n",
        "    dados = np.array(dados, dtype=\"float\") / 255\n",
        "    rotulos = np.array(rotulos)\n",
        "\n",
        "    # random_state(0) mesma divisão de dados se rodar novamente o mdeolo (garante consistencia de dados\n",
        "    # em diferentes configurações)\n",
        "    (X_train, X_test, Y_train, Y_test) = train_test_split(dados, rotulos, test_size=0.35, random_state=0)\n",
        "\n",
        "    lb = LabelBinarizer().fit(Y_train)\n",
        "    Y_train = lb.transform(Y_train)\n",
        "    Y_test = lb.transform(Y_test)\n",
        "\n",
        "    with open(nome_ia, 'wb') as arquivo_pickle:\n",
        "        pickle.dump(lb, arquivo_pickle)\n",
        "\n",
        "    #rede neural sequencial (fluxo em em pilha)\n",
        "    model = Sequential()\n",
        "\n",
        "    # (20,(5,5)) [= numero de filtros (20) ou mapas de caracteristicas diferentes\n",
        "    # (5,5) é o tamanho dos filtros\n",
        "    # padding = define o preenchimento com mesmas dimensoes (largura e altura) de entrada\n",
        "    # (20,20,1) imagem com 20 pixels e 1 canal (escala de cinza)\n",
        "    # introduzir não linearidade\n",
        "    model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20,20,1), activation=\"relu\"))\n",
        "\n",
        "    # reduz dimensinalidade matendo caracteristicas mais importantes\n",
        "    # (2,2) tamanho da janela\n",
        "    # strides(movimento da janela horizontal e vertical) ajuda a não \"overfitar\"\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    # (50, (5,5)) qtde de filtros (20) e tamanho do kernel (janelas da imagem)\n",
        "    # padding tipo de preenchimento same =mesma dimensão da entrada\n",
        "    model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "    #\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    # transforma saida em vetor unidimensional\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # conecta todos os neuronios conectados a neuronios da camada anterior\n",
        "    model.add(Dense(500, activation=\"relu\"))\n",
        "\n",
        "    # softmax (classificacao multiclasse)\n",
        "    model.add(Dense(number_options, activation=\"softmax\"))\n",
        "\n",
        "    # categorical_crossentropy (calcula previsoes dos rotulos do modelo e reais)\n",
        "    # otimizados ADAM (variante do gradiente descendente), atualiza pesos em funcao de perda\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "    epochs = 50\n",
        "\n",
        "    history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=number_options, epochs=epochs, verbose=1)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
        "    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "    ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "    legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "    ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "    ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "    legend = ax[1].legend(loc='best', shadow=True)\n",
        "\n",
        "    model.save(nome_modelo)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    treinar(57, \"letra\", \"rotulos_modelo_aula.dat\", \"modelo_treinado_aula.hdf5\")"
      ],
      "metadata": {
        "id": "ALLNyDkQ_9Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  - RESOLVER CAPTCHA\n",
        "\n",
        "# noise=qtde ruidos (quanto maior mais dificil reconhecer)\n",
        "def quebrar_captcha(noise, areas, ia_file, model_file, calculo, metodo):\n",
        "    with open(ia_file, \"rb\") as arquivo_tradutor:\n",
        "        lb = pickle.load(arquivo_tradutor)\n",
        "\n",
        "    modelo = load_model(model_file)\n",
        "\n",
        "    arquivos = glob.glob(\"resolver/*\")\n",
        "\n",
        "    tratar_captcha = tratar_imagem(noise, \"resolver\", arquivo_destino=\"resolver\")\n",
        "    arquivos = list(paths.list_images(\"resolver\"))\n",
        "\n",
        "    for arquivo in arquivos:\n",
        "        imagem = cv2.imread(arquivo)\n",
        "        imagem = cv2.cvtColor(imagem, cv2.COLOR_RGB2GRAY)\n",
        "        _, imagem = cv2.threshold(imagem, 0, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "        contornos, _ = cv2.findContours(imagem, calculo, metodo)\n",
        "\n",
        "        regiao_letras = []\n",
        "        previsao = []\n",
        "\n",
        "        for i,contorno in enumerate(contornos):\n",
        "\n",
        "            (x, y, l, a) = cv2.boundingRect(contorno)\n",
        "            area = cv2.contourArea(contorno)\n",
        "\n",
        "            if area > areas and x > 0 and y > 0:\n",
        "\n",
        "                # posicao x,y, largura e altura\n",
        "                regiao_letras.append((x,y,l,a))\n",
        "\n",
        "        regiao_letras = sorted(regiao_letras, key=lambda x: x[0])\n",
        "        imagem_final = cv2.merge([imagem] * 3)\n",
        "        i=0\n",
        "\n",
        "        for retangulo in regiao_letras:\n",
        "\n",
        "            x,y, largura, altura = retangulo\n",
        "            imagem_letra = imagem[y-2:y+altura + 2, x-1:x+largura+1]\n",
        "\n",
        "            imagem_letra = resize_to_fit(imagem_letra, 20, 20)\n",
        "\n",
        "            imagem_letra = np.expand_dims(imagem_letra, axis=2)\n",
        "            imagem_letra = np.expand_dims(imagem_letra, axis=0)\n",
        "\n",
        "            letra_prevista = modelo.predict(imagem_letra)\n",
        "            letra_prevista = lb.inverse_transform(letra_prevista)[0]\n",
        "            teste_letra = letra_prevista.split('_')\n",
        "            if len(teste_letra) == 2:\n",
        "                previsao.append(str(teste_letra[0]).upper())\n",
        "            else:\n",
        "                previsao.append(teste_letra[0])\n",
        "\n",
        "        texto_previsao = \"\".join(previsao)\n",
        "        print(texto_previsao)\n",
        "        return texto_previsao\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ia_file = \"rotulos_modelo_aula.dat\"\n",
        "    model_file = \"modelo_treinado_aula.hdf5\"\n",
        "    quebrar_captcha(10, 20, ia_file, model_file, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
      ],
      "metadata": {
        "id": "hevWVel6ZCGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}